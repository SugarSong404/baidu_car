# 前言
该文章旨在提供目标检测模型训练方法以及一些任务的判断与解决方案，相关代码请前往仓库[https://github.com/SugarSong404/baidu_car](https://github.com/SugarSong404/baidu_car)

# Det模型训练思路
Det模型的训练主要由我的队友**ybh**完成，所以我这里就不贴出训练代码了，只讲一讲思路
对一个模型，比如说神秘任务，大概需要无光、冷暖光、不同角度光、强光的数据集共1800张
如果是多类型模型，比方说是食材，则需要12000张
从中均匀选取个300-500张进行标注，就可以拿去练一个**自动标注模型**
这是因为我们发现
> 使用其它模型标出的数据集拿去paddle平台进行训练的精度要比全部亲手标高出不少，这样做省时省力效果还好，非常建议大家尝试
> 
自动标注模型采用yolov5，使用pytorch进行训练，我的训练脚本如下，注意yolov5请前往[yolo官方仓库](https://github.com/ultralytics/yolov5)自行下载

```python
import os
import sys
import subprocess
def main():
    root_dir = os.path.dirname(__file__)

    yolov5_dir = os.path.join(root_dir, "yolov5")

    data_yaml = os.path.join(root_dir, "data.yaml")

    epochs = 150
    batch_size = 16
    imgsz = 640
    weights = "yolov5s.pt" 

    train_script = os.path.join(yolov5_dir, "train.py")

    cmd = [
        sys.executable, train_script,
        "--img", str(imgsz),
        "--batch", str(batch_size),
        "--epochs", str(epochs),
        "--data", data_yaml,
        "--weights", weights,
        "--device", "0",
        "--project", os.path.join(root_dir, "runs/det"), 
        "--name", "det"
    ]

    print("Running training with command:")
    print(" ".join(cmd))

    result = subprocess.run(cmd, cwd=yolov5_dir)

    if result.returncode == 0:
        print("训练完成！")
    else:
        print("训练失败，请检查错误信息。")

if __name__ == "__main__":
    main()
```
训练完成后下运行

```powershell
python ./yolov5/export.py --data data.yaml --weights ./runs/train/exp/weights/best.pt --imgsz 640 --include onnx 
```
即可得到best.onnx文件，导入到软件`X-AnyLabeling`就可以自动标了，当然自动标不是放手不管，人还是要盯着防止出现标注不对的情况

**数据集录制脚本server.py与client.py以及自动标注模型工具我都会放在仓库的make_dataset目录中**
# Det模型的误判处理
正如`go.py`中写的那样
```python
self.wait_go()
drct = timed_call(fork_task, self)
timed_call(hanota_task, self, drct)
ann_flag = timed_call(bmi_task, self)
timed_call(ann_task, self, True)
timed_call(mys_task, self)
timed_call(bag_task, self, 0)
food1, food2  = timed_call(food_task, self)
timed_call(edu_task, self, food2)
has_bag = timed_call(bag_task, self, 1)
timed_call(cook_task, self, [food1, food2], has_bag)
timed_call(final_task, self, True)
```
我的任务是紧接着一个个执行的，每个模型只在需要用到它的一小段时间内使用，所以误判的影响也只会发生在一小段时间内
因此，只需要对这一小段时间可能的误判进行处理就几乎没有影响了

有诸多元素可以防止误判

>- 检测框的面积
> - 识别置信度
> - 检测框的上下左右边界离图像上下左右边界的距离（检测框在图像中的位置）
> - 检测框的长宽比
> - 检测框在多帧内的存在情况

一般两三个条件连判就没有误识别什么事了

# Det模型的对齐操作
执行任务最重要的就是对齐元素的位置，只有这样才能给“机械臂”一个夹取/放下等操作的容错
这里可以上个PID闭环，给一个恰当的kp即可稳当而精准地停在合适地位置
> 1.图像中心与检测框中心在图像水平方向上的距离 -> 车在前后方向上的速度
> 2.图像上/下边界与检测框上/下边界在图像竖直方向上的距离 -> 车在左右/前后方向上的速度

对于1来说，设定距离2-3帧内小于5个像素就停下效果就不错了，**我们还可以设定所谓的图像中心来控制车停在想要的位置，而不是先对齐真正图像中心再通过编码器前往需要的位置，不然对较低精度的编码器十分不友好**

对于2来说，**这个闭环的主要作用是调节车与目标元素之间的距离**，比如汉诺塔控制好距离后才能让机械臂吸在中心，比如控制好和终点元素的距离才可以用编码器撞老人和稳定入库。**如果靠近目标会丢失下边界那么就要选用上边界计算，如果是车库这种不会丢失下边界的就要用下边界判断，畸变更小**

我的PID直接使用了`simplepid`库，下面随便贴出一段`tasks/utils`中的函数表示大概的代码

```python
def align_det(car, det, id, tho, drct=1, region=None, timeout=5, frames = 1, pid_big = False, center = 320):
    t_start = time.time()
    nums = 0
    pid = car.pid_align_bag if pid_big else car.pid_align
    while True:
        if time.time() - t_start > timeout:
            raise TimeoutError("align_det 超时")
        img = car.cap_side.read()
        if img is None:continue 
        if region is not None:img = mask_img(img, region)
        det_res = det.predict(img)
        if det_res is None or 'boxes' not in det_res or len(det_res['boxes']) == 0:
            car.set_velocity(0.1, 0, 0)
            continue
        index = -1
        for i, box in enumerate(det_res['boxes']):
            if int(box[0]) == id:
                index = i
                break
        if index == -1:
            car.set_velocity(0, 0, 0)
            continue
        box = det_res['boxes'][index]
        dis = ((box[2] + box[4]) / 2) - center
        if abs(dis) < tho:nums+=1
        if nums > frames:break
        pid_output = pid(dis)
        car.set_velocity(pid_output*drct, 0, 0) 
    car.set_velocity(0, 0, 0)
```

# 各类元素思路简述
这里只讲简单的实现，更细节的操作，如*叠条件防误判*还请移步仓库看代码
## 三叉和汉诺塔
三叉没什么好讲的，编码器走到箭头脸上，判方向打角，循迹走一段固定距离到第一个圆柱旁，并以此时位置为编码器原点
在车前进的路上不断执行**看到新圆柱->判断圆柱类型->对齐新圆柱->记录圆柱位置**的操作
直到对齐最后一个圆柱，加上固定一段距离就是放置点的位置
*（ps:所以一分钟时间检查赛道非常重要，你要抓紧把最后一个圆柱摆在正中间，不然放不准）*
然后就是简单的**前往圆柱位置取圆柱->前往放置点放圆柱**循环直到完成
汉诺塔做完打角，为后面循迹减轻压力
## BMI、圆环和神秘任务
![image.png](https://i-blog.csdnimg.cn/img_convert/c9539985c52023a2a7e44602c39bdb81.png)
bmi非常简单，侧摄像头一直看，判到后对齐停下来，撞击识别完成
圆环的判据我在上一篇博客中说到，是角点图像上的一颗树，这棵树非常妙，作为进出圆环的判据都可以
做完bmi自动切换圆环循迹模型，圆环目标检测判到树则进入出园环状态，维持个1.5-2.5秒的圆环循迹模型就可以切回全局循迹模型
紧接着就是神秘任务，也是侧摄像头判定对齐秒了。关键就是放置问题，官模摄像头打角是可以超过90°的，所以可以往车身里面丢
## 沙包
![image.png](https://i-blog.csdnimg.cn/img_convert/a7a0d2f4bb137f809ededb0b74adaa74.png)
沙包找了圆桶当判据，对齐后就可以直接开始投了，这里容错很大，所以选择远处的圆桶进行对齐完全没有问题
这里要提到我之前说的，不一定要用图像中心作为对齐的中心，不然的话由于摄像头与投射装置有一段距离，还得倒退，多次一举了
## 取食材
取食材前可以快速循迹跑，然后看到食材的一瞬间减速，后面对齐文本
*这里提一嘴，我所有的对齐文本都是用食材det模型中的文本判定的而非ocr模型*
对齐文本后以该位置为**编码器原点**，识别得到食材是什么，对齐食材吸取食材
*继续提一嘴，由于官模本身的原因，一下子可能看不全最前面的食材导致失败不到，所以几帧内没找到就以该慢速前进接着找*
然后回到**编码器原点**，转换摄像头方向，识别另一边的文本，然后重复一套对齐食材加吸取即可

**注意每个食材夹取操作执行后，再对位置进行几帧det判定，没有判到才代表成功夹取了，这对教育题和放置食材非常重要**
## 教育
![1756691917486.png](https://i-blog.csdnimg.cn/img_convert/29d4fd89e5cd33c1d394de606abb7a1a.png)
教育的判定是通过红框中的特征训练的模型进行的，判到后对齐，取该位置为编码器原点，那么与四个选项的距离都是固定的，就很好前往了
**获取答案进行推动前就要看取食材操作时究竟有没有夹到第二个食材，即手上有没有物块。** 空嘴推动和物块推动的距离、高度都是不一样的，这样能保证失误了没夹到也不丢分。
## 放食材，撞老人和终点
**放食材的前置条件是做完第二个沙包**
这样摄像头转过来的时候是一定能看到前两段文本的，进行第一次识别判定，如果答案不在其中就向前走
**走到视野内没有文本才开始后两段文本的检索，这样能防止把前两段文本当作后两段文本去对齐**
确认答案后设置此位置为编码器原点，然后走不同距离放置物块即可
**之前取食材的判定现在就可以在没夹到某个食材时不进行它的放置操作，避免浪费时间**
终点与撞老人，简单，无需多言。练了个终点模型，控制距离后停车，然后一套编码器操作结束了。
# 任务综述后话
**向我的所有队友致谢！！！！！大家都经历了一段哪怕疲惫不堪也要奋斗、精益求精的时光**

Det模型练好，一系列API准备好，后面写各类任务就如鱼得水
**另外我推荐明年用官模的朋友自配陀螺仪和编码器，我今年用官模真的有点心累。
用自制车最好，自制车显然有车身轻便（同样电机跑起来更快更轻松），体积较小（更不容易出界），机械臂操作快（官模丝杠上升下降非常慢），用自己喜欢的下位机（更容易地换各类传感器）等优点**
我这套方案只是在不断地去降低容错，仍然无法做到百分百的准确，只是为大家提供一种思路
抛砖引玉，有更好想法的大佬也可以和我交流讨论或在评论区留言